<!DOCTYPE html><html lang="en" class="__variable_871a3d __variable_e566b6"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/bayes-bits-brains/_next/static/media/1f3fe8c6df3d47c1-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/bayes-bits-brains/_next/static/media/558ca1a6aa3cb55e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/problens-web/fig/eliza.png"/><link rel="stylesheet" href="/bayes-bits-brains/_next/static/css/dbd2812aeb31ae93.css" data-precedence="next"/><link rel="stylesheet" href="/bayes-bits-brains/_next/static/css/5eacd01f773eed7f.css" data-precedence="next"/><link rel="stylesheet" href="/bayes-bits-brains/_next/static/css/622677e989ec6b9c.css" data-precedence="next"/><link rel="stylesheet" href="/bayes-bits-brains/_next/static/css/8870e1553eaf2585.css" data-precedence="next"/><link rel="stylesheet" href="/bayes-bits-brains/_next/static/css/13ab9833c5f6a889.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/bayes-bits-brains/_next/static/chunks/webpack-9a476a05d384b821.js"/><script src="/bayes-bits-brains/_next/static/chunks/11eacf67-36e122528944b7c0.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/954-75be81b03e98094e.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/main-app-68bf59435228f0c4.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/45233be0-cba42a3c5454822d.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/4bbad5ef-2b7eebeba98386a5.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/f885ef2c-649d91f122a11dff.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/0133708f-65d46efc97e0f93d.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/91c6c604-01c8ba6fb8219fe8.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/950-e6e0e01ad2983f53.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/390-7b8633ed8924eb08.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/582-781968895face3a7.js" async=""></script><script src="/bayes-bits-brains/_next/static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js" async=""></script><meta name="next-size-adjust" content=""/><title>Bayes, bits &amp; brains</title><meta name="description" content="Bayes, bits &amp; brains"/><script src="/bayes-bits-brains/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased"><div class="min-h-screen flex flex-col bg-white"><header class="sticky left-0 right-0 top-0 z-50 bg-white/80 backdrop-blur-sm gap-0 transition-all duration-200 py-2"><div class="max-w-[var(--content-width)] mx-auto px-4 py-6 flex h-16 items-center justify-end"><button class="lg:hidden p-2 text-neutral-600 hover:text-neutral-900" aria-label="Toggle menu"><svg class="h-6 w-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></header><div class="fixed inset-0 z-40 lg:hidden transition-opacity duration-300 opacity-0 pointer-events-none"><div class="top-16 fixed inset-0 bg-neutral-100/80 backdrop-blur-sm shadow-xl"></div><div class="top-16 fixed inset-x-0 bottom-0 bg-white shadow-xl transition-transform duration-300 overflow-y-auto -translate-y-full"><div class="w-full min-h-full" style="margin-left:calc(max((100% - var(--content-width)) / 2 + 1rem, 2rem))"><nav class="Sidebar_sidebar__G7Mzs py-6 text-lg"><div class="mb-6"><a class="text-2xl font-semibold text-neutral-900 hover:text-neutral-600 transition-colors" href="/bayes-bits-brains/">Bayes, bits &amp; brains</a></div><div class="Sidebar_scrollableContent__WtZmB"><div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/00-riddles/">Riddles</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/01-kl_intro/">Bayes &amp; KL divergence</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/02-crossentropy/">Crossentropy &amp; Entropy</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/03-entropy_properties/">KL &amp; Entropy properties</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/04-mle/">Maximum likelihood</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/05-max_entropy/">Maximum entropy</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/07-machine_learning/">Loss functions</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/08-coding_theory/">Coding theory</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/09-kolmogorov/">Kolmogorov complexity</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div class="mt-6 pt-4 border-t border-gray-200"><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/about/">About</a></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/resources/">Resources</a></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/bonus/">Graveyard</a></li></ul></div></div></nav></div></div></div><div class="flex-1"><nav class="Sidebar_sidebar__G7Mzs xl:w-60 lg:w-52 hidden lg:block fixed top-16 bottom-0 pt-16 text-base" style="left:var(--sidebar-offset)"><div class="mb-6"><a class="text-2xl font-semibold text-neutral-900 hover:text-neutral-600 transition-colors" href="/bayes-bits-brains/">Bayes, bits &amp; brains</a></div><div class="Sidebar_scrollableContent__WtZmB"><div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/00-riddles/">Riddles</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/01-kl_intro/">Bayes &amp; KL divergence</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/02-crossentropy/">Crossentropy &amp; Entropy</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/03-entropy_properties/">KL &amp; Entropy properties</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/04-mle/">Maximum likelihood</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/05-max_entropy/">Maximum entropy</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/07-machine_learning/">Loss functions</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div><div class="my-4 border-t border-gray-200"></div><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/08-coding_theory/">Coding theory</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/09-kolmogorov/">Kolmogorov complexity</a><div class="Sidebar_subsections__4JMe7 false"><div class="Sidebar_subsectionWrapper__tUx1X Sidebar_subsectionWrapperHidden__3D_C_"></div></div></li></ul></div><div class="mt-6 pt-4 border-t border-gray-200"><ul class="Sidebar_list__I5HfV"><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/about/">About</a></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/resources/">Resources</a></li><li class="Sidebar_item__IbyhT"><a class="Sidebar_link__NjnkI " href="/bayes-bits-brains/bonus/">Graveyard</a></li></ul></div></div></nav><main class="Page_main__cWiGN max-w-[var(--content-width)] mx-auto px-4 pt-12 pb-8"><article class="Page_article__A_Nud prose prose-neutral max-w-none"><h1>Kolmogorov Complexity</h1>
<p>In the <a href="/08-coding_theory">previous chapter</a>, we saw what entropy tells us about compressing strings. If we treat letters independently, coding theory is especially powerful. But that&#x27;s an assumption that good compression algorithms can&#x27;t make.</p>
<p>Kolmogorov complexity is the ultimate limit for how much a file can be compressed. This makes it a very powerful theoretical concept to have in our dictionary!</p>
<!-- -->
<div class="my-6 rounded-lg overflow-hidden bg-amber-50 border border-amber-200"><div class="px-4 py-3 border-b border-amber-200"><div class="font-medium text-base text-amber-800 flex items-center gap-2"><span class="text-lg">💡</span>If there is one thing you remember from this chapter...</div></div><div class="px-4 py-3 text-base leading-relaxed text-gray-700"><p>Kolmogorov complexity of an object is the length of its shortest specification. This is the ultimate limit of compression.</p></div></div>
<h2>The Mandelbrot Set</h2>
<p>Take a good look at the following picture.<sup id="ref-footnote-1-1" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">1</span></sup> It shows a so called Mandelbrot set -- we color each pixel of the plane based on how quickly a certain sequence of numbers shoots to infinity.</p>
<p>If you take print screen of this picture and save it on your disk, it&#x27;s going to take a few MB. But what if you instead save the <em>instruction</em> for how to create this image? All relevant ingredients are stored in the two boxes below the picture - the formula used to create it, and the coordinates of the plane you are looking at. We are talking about less than kilobyte of memory now.</p>
<div class="w-full space-y-4"><div class="relative w-full h-96 md:h-[500px] border border-gray-300 rounded-lg overflow-hidden" style="touch-action:none"><canvas class="w-full h-full cursor-move"></canvas></div><div class="flex flex-col sm:flex-row gap-4 items-center"><div class="flex items-center gap-2"><label for="iterations" class="text-sm font-medium">Max Iterations:</label><input id="iterations" type="range" min="50" max="2000" class="w-32" value="50"/><span class="text-sm w-12">50</span></div><button class="transition-colors rounded-md bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 text-sm float-right mb-2 ">Reset</button><div class="text-sm text-gray-600">Drag • Scroll to zoom • Double-click</div></div><div class="space-y-4"><div class="bg-gray-50 p-4 rounded-lg border-2 border-gray-200"><div class="font-medium mb-4 text-center text-gray-700">↓ Kolmogorov complexity of the picture ↓</div><div class="flex flex-col md:flex-row gap-4"><div class="flex-1 border border-gray-300 bg-white p-4 rounded-lg"><div class="font-medium mb-3 text-center">Mandelbrot Set Formula</div><div class="text-center space-y-2"><div>z₀ = 0, z<sub>n+1</sub> = z<sub>n</sub>² + c</div><div>c ∈ M if |z<sub>n</sub>| remains bounded</div><div class="text-sm text-gray-600">Max iterations: <!-- -->50</div></div></div><div class="flex-1 border border-gray-300 bg-white p-4 rounded-lg"><div class="font-medium mb-3 text-center">Viewport Coordinates</div><div class="font-mono text-sm space-y-1"><div>Left: <!-- -->-2.50</div><div>Right: <!-- -->1.50</div><div>Top: <!-- -->-1.50</div><div>Bottom: <!-- -->1.50</div></div></div></div></div></div></div>
<p>This is the gist of Kolmogorov complexity. For any given object - say, represented as a binary string - it&#x27;s Kolmogorov complexity is the length of the shortest program that prints that string.</p>
<p>Here are a few more examples.</p>
<ul>
<li>Although digits of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> have many random-like properties, the Kolmogorov complexity of its first million digits is extremely small. That&#x27;s because there are some <a href="https://cs.uwaterloo.ca/~alopez-o/math-faq/mathtext/node12.html">extremely short</a> programs printing it.</li>
<li>Larger numbers (written down in binary) typically have larger Kolmogorov complexity. But there are huge numbers like <span></span> with very small Kolmogorov complexity.</li>
<li>Whenever you can ZIP a file to a size of 100MB, you can say that &quot;Kolmogorov complexity of the file is at most 100MB&quot;</li>
<li>The Hutter&#x27;s challenge from <a href="/08-coding_theory">coding theory chapter</a> is about estimating the Kolmogorov complexity of 1GB of Wikipedia</li>
<li>If you keep flipping a coin <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> times, the resulting sequence is likely to have Kolmogorov complexity of about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>. There&#x27;s no good way of compressing it.</li>
</ul>
<h2>Choosing the language</h2>
<p>There is an awkward problem with the definition of Kolmogorov complexity. It&#x27;s the length of the shortest program -- but what programming language do we use? Python? C? Assembly? Turing machine? Do we allow languages <em>and</em> libraries? Printing million digits of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> can then reduce to this:</p>
<pre><code>import sympy
print(sympy.N(sympy.pi, 1000000))
</code></pre>
<p>The important insight is that, at least if we stay on the theoretical side of things, the choice does not matter that much. The trick is that in any (<a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing-complete</a>) programming language, we can build an <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)">interpreter</a> of any other programming language.
Interpreter is a piece of code that reads a code written in some other language, and executes its instructions.</p>
<p>In any reasonable programming language, you can write an interpreter for any other reasonable language in at most, say, 1MB. But this means that Kolmogorov complexity of any object is fixed &#x27;up to 1MB&#x27;: If you have a 100MB Python script that prints the file, then you have a 101MB C, Assembly, Java, ... script printing the same file - just write a code where the first 1MB is an interpreter of Python tasked to execute the remaining 100MB.</p>
<p>So for large objects (like the 1GB Wikipedia file from Hutter&#x27;s prize), there&#x27;s nothing awkward in using Kolmogorov complexity. The flip side is that it&#x27;s pretty meaningless to argue whether the Kolmogorov complexity of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> is 200 or 300 bytes. That difference depends on the choice of programming language too much.</p>
<h2>Kolmogorov vs entropy: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>≈</mo><mi>H</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E[K(x)] \approx H(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span></span></span></span></h2>
<p>Both Kolmogorov complexity and entropy are trying to measure something very similar: complexity, information, compression limit. Naturally, there are closely connected. The connection goes like this: If you have a reasonable distribution (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span>) over bit strings and you sample from it (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span>), then the entropy of the distribution is roughly equal to the expected Kolmogorov complexity of the sample. I.e., <span></span>.</p>
<div class="my-6 rounded-lg overflow-hidden" style="background-color:#f5f5f5"><div class="px-4 py-3 border-b border-neutral-200"><div class="font-medium text-base">Example: uniform distribution</div></div><div class="px-4 py-3 text-base leading-relaxed"><p>Let&#x27;s see why this is true on an example. Take a sequence of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> fair coin flips. This is a uniform distribution over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span> binary strings of length <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>. The entropy of this distribution is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>. Now let&#x27;s examine the Kolmogorov complexity.</p><p>On one hand, the Kolmogorov complexity of any <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>-bit string is at most <div class="katex-display-wrapper" style="overflow-x:auto;overflow-y:hidden;-webkit-overflow-scrolling:touch;width:100%;margin:1rem 0;text-align:center"><span style="display:inline-block"></span></div> That&#x27;s because in any (reasonable) language, you can just print the string:</p><pre><code>print(&#x27;01000...010110&#x27;)
</code></pre><p>But can the average Kolmogorov complexity be much smaller than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>? Notice that our uniform distribution contains many strings with very small Kolmogorov complexity, like the string <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>000</mn><mo>…</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">000\dots 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">000</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0</span></span></span></span>. The reason why those special snowflakes don&#x27;t really matter on average is <a href="/08-coding_theory">coding theory</a>.
We can construct a concrete code like this: for any string in our distribution, its code name is the shortest program that prints it.<sup id="ref-footnote-2-2" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">2</span></sup> The average length of this code is exactly <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E[K(x)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span></span></span></span>. But <a href="/08-coding_theory#source-coding">we have seen</a> that any code has its average length at least as big as the entropy. Hence, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>≥</mo><mi>H</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">E[K(x)] \ge H(X) = n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> and we have the formula:</p><div class="katex-display-wrapper" style="overflow-x:auto;overflow-y:hidden;-webkit-overflow-scrolling:touch;width:100%;margin:1rem 0;text-align:center"><span style="display:inline-block"></span></div></div></div>
<p>If you look at above proof sketch, you can notice that we did not really use that the distribution is uniform, it works pretty much for any distribution.<sup id="ref-footnote-3-3" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">3</span></sup></p>
<p>However, the case of a uniform distribution is the most interesting: It tells us that most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>-bit strings can&#x27;t really be compressed, since their Kolmogorov complexity is close to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>! In fact, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>-bit strings with Kolmogorov complexity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">\ge n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> are called <em>Kolmogorov random</em>, to highlight the insight that <strong>bits are random if we can&#x27;t compress them</strong>.</p>
<div class="Expand_expand__enJz_"><div class="Expand_header__Q6jAu" style="background-color:#f5f5f5"><div class="Expand_headline__Bgb1v">Long runs</div><div class="Expand_arrow__LMPES "><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 4L6 8L10 4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div>
<h2>Prediction, compression, and the Chinese room</h2>
<p>In previous chapter, we talked about how prediction and compression are closely related. It may have looked a bit like some kind of algebraic trick - coincidentally, surprise is measured as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">\log 1/p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1/</span><span class="mord mathnormal">p</span></span></span></span> and lengths of good code name is also <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">\log 1/p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1/</span><span class="mord mathnormal">p</span></span></span></span>, so there&#x27;s the connection between prediction and coding.
Kolmogorov complexity gives a smooth language to talk about this connection. In particular, I find it especially helpful that we can talk about compression / Kolmogorov complexity without talking about probability distributions.</p>
<p>Let&#x27;s say we want to discuss how LLMs are &quot;good at predicting the next token on Wikipedia&quot; and make it more mathematically precise. Using the language of cross-entropy and entropy is a bit awkward - it has to involve some kind of distribution over inputs. We have to imagine some kind of abstruse probability distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span> over thoughts about the world written in English. Then, let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span></span></span></span> be the distribution over texts generated by running our LLM. The technical sense in which the LLM &quot;is good at predicting&quot; is that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(p,q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mclose">)</span></span></span></span> is small.</p>
<p>Using the language of compression, we can reformulate &quot;being good at predicting Wikipedia&quot; as &quot;being good at compressing Wikipedia&quot;. For me, this is much more tangible! LLMs are simply smart enough not to find &quot;Wikipedia&quot; that surprising - as measured in bits that we have to store so that the LLM can recover the original text from them. This story about what&#x27;s happening in LLMs does not require arguing about any distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span> over all English texts.</p>
<p>Here&#x27;s a concrete example that helps illustrate these concepts. A philosopher called <a href="https://en.wikipedia.org/wiki/John_Searle">John Searle</a> once proposed a thought experiment called <a href="https://en.wikipedia.org/wiki/Chinese_room">Chinese room</a>.</p>
<p>Let me quickly explain the gist. <sup id="ref-footnote-4-4" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">4</span></sup> If you are from the older generation like me, you might remember that pre-2022, there was a thing called <a href="https://en.wikipedia.org/wiki/Turing_test">Turing test</a>:<sup id="ref-footnote-5-5" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">5</span></sup> Imagine that you can chat for a few minutes with an entity that is either a human, or an AI impersonating a human. If you can&#x27;t reliably tell the two cases apart, Turing claims that we should concede that the AI is intelligent.</p>
<p>But Searle objects: What if the AI was just a long list of rules? (In his experiment, he imagines a person locked in a room with a Chinese conversation rulebook) This was actually how some pre-deep learning AIs faked their way through short (5 minutes) Turing test games. The AIs were just an incredibly long lists of pattern matching rules like &quot;If they seem to ask you about your favorite artist, tell them Madonna and ask them about their favorite artist. &quot; This works for very short conversations, since it was relatively predictable what kind of questions the human judges are typically asking.</p>
<div class="my-6"><div class="w-full flex justify-center"><div class="rounded shadow-sm overflow-hidden bg-white" style="max-width:100%"><img src="/problens-web/fig/eliza.png" alt="ELIZA" style="cursor:pointer" class="max-w-full h-auto object-contain block"/></div></div><div class="text-center text-sm italic font-medium text-gray-700 max-w-2xl mx-auto min-h-[1.5em] mt-0.5 px-4 py-0.5"><p>Pre-deep-learning chatbots like ELIZA are mostly just lists of common phrases, especially questions that pretend to be relevant. If you keep adding IFs and ELSEs, you get better models of human language. But there&#x27;s no compression happenning, so the chatbot does not really generalize to new situations.</p></div></div>
<p>The problem with this approach is that <a href="https://arxiv.org/pdf/1108.1791">it gets exponentially harder</a> - for each additional minute of the immitation game, the number of rules included in the intelligence fakers has to grow by a multiplicative factor. That&#x27;s because there is no <em>compression</em> happening in those programs - they were not trying to <em>predict</em> what happens in human-like conversations, they were just trying to list all of them. Thus, such programs never really <em>generalized</em>, they did not lead to new, interesting insights. And, Searle has a very good point that even if the programs can fool people on Turing test for a few minutes, there is not really much of an <em>understanding</em> happening.</p>
<p>This is of course very different for current AIs. As we now understand, they are literally trained to <em>predict</em> human conversations and writings. Or, equivalently, they are trying to <em>compress</em> them. This compression is the crucial difference from the earlier Turing-test-fakers. The architects of current AI like Ilya Sutskever understand this difference extremely well and it was the reason why they were optimistic about the overall approach of training general intelligence by modelling text. They understood that being good on the &quot;simplistic&quot; task of predicting the next token does not only force you to learn English words (GPT-1) or the basic grammar of a couple of languages (GPT-2). To get really good at predicting the next token, you have to <a href="https://www.dwarkesh.com/p/ilya-sutskever">understand the underlying reality that led to the creation of that token</a>. Understanding reality partially consists of learning facts, but more importantly, it requires intelligence to combine them. <sup id="ref-footnote-6-6" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">6</span></sup></p>
<h2>Solomonoff prior &amp; induction</h2>
<p>What&#x27;s the most natural distribution over all (finite) binary strings, if what we care about is their Kolmogorov complexity? The <a href="/04-max_entropy">maximum entropy principle</a> says we should consider the distribution <span></span>, for some <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span>. In a minute, we will see that the right <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span> is such that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>∝</mo><msup><mn>2</mn><mrow><mo>−</mo><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">p(x) \propto 2^{-K(x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.888em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> <sup id="ref-footnote-7-7" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">7</span></sup> This distribution is called <em>Solomonoff prior</em>. <sup id="ref-footnote-8-8" class="Footnotes_footnote__9N0Ba" tabindex="0" role="button" data-state="closed"><span class="Footnotes_footnote-link__l83hx">8</span></sup></p>
<p>It&#x27;s called <em>prior</em> because this is how we typically want to use this distribution. Similarly to other maximum entropy distributions, this is where should start before we start making observations and updating it. I find it philosophically very appealing, feel free to check the expand boxes.</p>
<div class="Expand_expand__enJz_"><div class="Expand_header__Q6jAu" style="background-color:#fff5f5"><div class="Expand_advancedIcon__0rGTu" title="This is an advanced section">⚠️</div><div class="Expand_headline__Bgb1v">Solomonoff induction</div><div class="Expand_arrow__LMPES "><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 4L6 8L10 4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div>
<div class="Expand_expand__enJz_"><div class="Expand_header__Q6jAu" style="background-color:#fff5f5"><div class="Expand_advancedIcon__0rGTu" title="This is an advanced section">⚠️</div><div class="Expand_headline__Bgb1v">Solving epistemology</div><div class="Expand_arrow__LMPES "><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 4L6 8L10 4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div>
<div class="Expand_expand__enJz_"><div class="Expand_header__Q6jAu" style="background-color:#fff5f5"><div class="Expand_advancedIcon__0rGTu" title="This is an advanced section">⚠️</div><div class="Expand_headline__Bgb1v">🐘 Von Neumann&#x27;s elephant &amp; overfitting</div><div class="Expand_arrow__LMPES "><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 4L6 8L10 4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div>
<div class="Expand_expand__enJz_"><div class="Expand_header__Q6jAu" style="background-color:#fff5f5"><div class="Expand_advancedIcon__0rGTu" title="This is an advanced section">⚠️</div><div class="Expand_headline__Bgb1v">AIC &amp; BIC model selection</div><div class="Expand_arrow__LMPES "><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 4L6 8L10 4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div><div class="mt-16 pt-8 border-t border-gray-200"><div class="flex justify-between items-center"><div class="flex-1"><a class="inline-flex items-center text-blue-600 hover:text-blue-800 transition-colors" href="/bayes-bits-brains/08-coding_theory/"><svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path></svg><div class="text-left"><div class="text-sm text-gray-500">Previous</div><div class="font-medium">Coding theory</div></div></a></div><div class="flex-1 text-right"></div></div></div></article></main></div><footer class="mt-4"><div class="max-w-screen-xl mx-auto px-4 sm:px-6 lg:px-8"><div class="pt-4 pb-12" style="margin-left:calc(max((100% - var(--content-width)) / 2 + 1rem, 0rem))"><p class="text-base text-neutral-500"></p></div></div></footer></div><script src="/bayes-bits-brains/_next/static/chunks/webpack-9a476a05d384b821.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:\"$Sreact.strict_mode\"\n4:I[1063,[],\"\"]\n5:I[11483,[],\"\"]\n7:I[95125,[],\"OutletBoundary\"]\na:I[95125,[],\"ViewportBoundary\"]\nc:I[95125,[],\"MetadataBoundary\"]\ne:I[31954,[],\"\"]\n:HL[\"/bayes-bits-brains/_next/static/media/1f3fe8c6df3d47c1-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/bayes-bits-brains/_next/static/media/558ca1a6aa3cb55e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/bayes-bits-brains/_next/static/css/dbd2812aeb31ae93.css\",\"style\"]\n:HL[\"/bayes-bits-brains/_next/static/css/5eacd01f773eed7f.css\",\"style\"]\n:HL[\"/bayes-bits-brains/_next/static/css/622677e989ec6b9c.css\",\"style\"]\n:HL[\"/bayes-bits-brains/_next/static/css/8870e1553eaf2585.css\",\"style\"]\n:HL[\"/bayes-bits-brains/_next/static/css/13ab9833c5f6a889.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"G9LV8pwmmB789ZWVZT0j8\",\"p\":\"/bayes-bits-brains\",\"c\":[\"\",\"09-kolmogorov\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"path\",\"09-kolmogorov\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/bayes-bits-brains/_next/static/css/dbd2812aeb31ae93.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/bayes-bits-brains/_next/static/css/5eacd01f773eed7f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/bayes-bits-brains/_next/static/css/622677e989ec6b9c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/bayes-bits-brains/_next/static/css/8870e1553eaf2585.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"4\",{\"rel\":\"stylesheet\",\"href\":\"/bayes-bits-brains/_next/static/css/13ab9833c5f6a889.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_871a3d __variable_e566b6\",\"children\":[\"$\",\"$2\",null,{\"children\":[[\"$\",\"body\",null,{\"className\":\"antialiased\",\"children\":\"$L3\"}],\"$undefined\"]}]}]]}],{\"children\":[[\"path\",\"09-kolmogorov\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",\"$undefined\",null,[\"$\",\"$L7\",null,{\"children\":[\"$L8\",\"$L9\",null]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"UybA7_RucoT1rWQskyQam\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:I[79444,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n10:I[60544,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n11:I[5340,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n12:I[47950,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"\"]\n3:[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col bg-white\",\"children\":[[\"$\",\"$Lf\",null,{}],[\"$\",\"$L10\",null,{}],[\"$\",\"d"])</script><script>self.__next_f.push([1,"iv\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"$L11\",null,{\"className\":\"xl:w-60 lg:w-52 hidden lg:block fixed top-16 bottom-0 pt-16 text-base\",\"style\":{\"left\":\"var(--sidebar-offset)\"}}],[\"$\",\"main\",null,{\"className\":\"Page_main__cWiGN max-w-[var(--content-width)] mx-auto px-4 pt-12 pb-8\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-gray-900 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-700 mb-4\",\"children\":\"Page Not Found\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"The page you're looking for doesn't exist or has been moved.\"}],[\"$\",\"$L12\",null,{\"href\":\"/\",\"className\":\"inline-block bg-blue-600 text-white px-6 py-3 rounded-lg hover:bg-blue-700 transition-colors\",\"children\":\"Go Home\"}]]}]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"footer\",null,{\"className\":\"mt-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-screen-xl mx-auto px-4 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"pt-4 pb-12\",\"style\":{\"marginLeft\":\"calc(max((100% - var(--content-width)) / 2 + 1rem, 0rem))\"},\"children\":[\"$\",\"p\",null,{\"className\":\"text-base text-neutral-500\"}]}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"13:I[10572,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"EquationProvider\"]\n14:I[36185,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"CitationsProvider\"]\n15:I[44464,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"FootnotesProvider\"]\n16:I[75154,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n17:I[44464,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5e"])</script><script>self.__next_f.push([1,"f-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"Footnote\"]\n18:I[18469,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n19:I[61803,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n1a:I[23229,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n1b:I[66704,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93"])</script><script>self.__next_f.push([1,"d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n1c:I[1896,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n1d:I[16900,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"default\"]\n1e:I[44464,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/chunks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"Footnotes\"]\n1f:I[36185,[\"683\",\"static/chunks/45233be0-cba42a3c5454822d.js\",\"338\",\"static/chunks/4bbad5ef-2b7eebeba98386a5.js\",\"932\",\"static/chunks/f885ef2c-649d91f122a11dff.js\",\"755\",\"static/chunks/0133708f-65d46efc97e0f93d.js\",\"269\",\"static/chunks/91c6c604-01c8ba6fb8219fe8.js\",\"950\",\"static/chunks/950-e6e0e01ad2983f53.js\",\"390\",\"static/ch"])</script><script>self.__next_f.push([1,"unks/390-7b8633ed8924eb08.js\",\"582\",\"static/chunks/582-781968895face3a7.js\",\"180\",\"static/chunks/app/%5B...path%5D/page-4c83be7a70b80924.js\"],\"References\"]\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"$L13\",null,{\"children\":[\"$\",\"$L14\",null,{\"data\":{},\"children\":[\"$\",\"$L15\",null,{\"children\":[\"$\",\"article\",null,{\"className\":\"Page_article__A_Nud prose prose-neutral max-w-none\",\"children\":[[[\"$\",\"h1\",null,{\"children\":\"Kolmogorov Complexity\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In the \",[\"$\",\"$L16\",null,{\"href\":\"08-coding_theory\",\"children\":\"previous chapter\"}],\", we saw what entropy tells us about compressing strings. If we treat letters independently, coding theory is especially powerful. But that's an assumption that good compression algorithms can't make.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Kolmogorov complexity is the ultimate limit for how much a file can be compressed. This makes it a very powerful theoretical concept to have in our dictionary!\"}],\"\\n\",\"\\n\",[\"$\",\"div\",null,{\"className\":\"my-6 rounded-lg overflow-hidden bg-amber-50 border border-amber-200\",\"children\":[[\"$\",\"div\",null,{\"className\":\"px-4 py-3 border-b border-amber-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-medium text-base text-amber-800 flex items-center gap-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-lg\",\"children\":\"💡\"}],\"If there is one thing you remember from this chapter...\"]}]}],[\"$\",\"div\",null,{\"className\":\"px-4 py-3 text-base leading-relaxed text-gray-700\",\"children\":[\"$\",\"p\",null,{\"children\":\"Kolmogorov complexity of an object is the length of its shortest specification. This is the ultimate limit of compression.\"}]}]]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"The Mandelbrot Set\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Take a good look at the following picture.\",[\"$\",\"$L17\",null,{\"children\":\"Be careful, though, excessive zooming may result in psychedelic experience. \"}],\" It shows a so called Mandelbrot set -- we color each pixel of the plane based on how quickly a certain sequence of numbers shoots to infinity.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"If you take print screen of this picture and save it on your disk, it's going to take a few MB. But what if you instead save the \",[\"$\",\"em\",null,{\"children\":\"instruction\"}],\" for how to create this image? All relevant ingredients are stored in the two boxes below the picture - the formula used to create it, and the coordinates of the plane you are looking at. We are talking about less than kilobyte of memory now.\"]}],\"\\n\",[\"$\",\"$L18\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"This is the gist of Kolmogorov complexity. For any given object - say, represented as a binary string - it's Kolmogorov complexity is the length of the shortest program that prints that string.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here are a few more examples.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Although digits of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"π\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}]]}]}]]}],\" have many random-like properties, the Kolmogorov complexity of its first million digits is extremely small. That's because there are some \",[\"$\",\"$L16\",null,{\"href\":\"https://cs.uwaterloo.ca/~alopez-o/math-faq/mathtext/node12.html\",\"children\":\"extremely short\"}],\" programs printing it.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Larger numbers (written down in binary) typically have larger Kolmogorov complexity. But there are huge numbers like \",[\"$\",\"$L19\",null,{\"math\":\"3^{3^{3^{3^3}}}\"}],\" with very small Kolmogorov complexity.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Whenever you can ZIP a file to a size of 100MB, you can say that \\\"Kolmogorov complexity of the file is at most 100MB\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"The Hutter's challenge from \",[\"$\",\"$L16\",null,{\"href\":\"08-coding_theory\",\"children\":\"coding theory chapter\"}],\" is about estimating the Kolmogorov complexity of 1GB of Wikipedia\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"If you keep flipping a coin \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\" times, the resulting sequence is likely to have Kolmogorov complexity of about \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\". There's no good way of compressing it.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Choosing the language\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"There is an awkward problem with the definition of Kolmogorov complexity. It's the length of the shortest program -- but what programming language do we use? Python? C? Assembly? Turing machine? Do we allow languages \",[\"$\",\"em\",null,{\"children\":\"and\"}],\" libraries? Printing million digits of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"π\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}]]}]}]]}],\" can then reduce to this:\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"import sympy\\nprint(sympy.N(sympy.pi, 1000000))\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The important insight is that, at least if we stay on the theoretical side of things, the choice does not matter that much. The trick is that in any (\",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Turing_completeness\",\"children\":\"Turing-complete\"}],\") programming language, we can build an \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Interpreter_(computing)\",\"children\":\"interpreter\"}],\" of any other programming language.\\nInterpreter is a piece of code that reads a code written in some other language, and executes its instructions.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"In any reasonable programming language, you can write an interpreter for any other reasonable language in at most, say, 1MB. But this means that Kolmogorov complexity of any object is fixed 'up to 1MB': If you have a 100MB Python script that prints the file, then you have a 101MB C, Assembly, Java, ... script printing the same file - just write a code where the first 1MB is an interpreter of Python tasked to execute the remaining 100MB.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"So for large objects (like the 1GB Wikipedia file from Hutter's prize), there's nothing awkward in using Kolmogorov complexity. The flip side is that it's pretty meaningless to argue whether the Kolmogorov complexity of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"π\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}]]}]}]]}],\" is 200 or 300 bytes. That difference depends on the choice of programming language too much.\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":[\"Kolmogorov vs entropy: \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mo\",null,{\"children\":\"≈\"}],[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"X\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[K(x)] \\\\approx H(X)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05764em\"},\"children\":\"E\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"[\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")]\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"≈\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07847em\"},\"children\":\"X\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]]}]]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Both Kolmogorov complexity and entropy are trying to measure something very similar: complexity, information, compression limit. Naturally, there are closely connected. The connection goes like this: If you have a reasonable distribution (\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"X\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"X\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07847em\"},\"children\":\"X\"}]]}]}]]}],\") over bit strings and you sample from it (\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"x\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"x\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}]]}]}]]}],\"), then the entropy of the distribution is roughly equal to the expected Kolmogorov complexity of the sample. I.e., \",[\"$\",\"$L19\",null,{\"displayMode\":false,\"math\":\"E[K(x)] \\\\approx H(X)\"}],\".\"]}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"my-6 rounded-lg overflow-hidden\",\"style\":{\"backgroundColor\":\"#f5f5f5\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"px-4 py-3 border-b border-neutral-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-medium text-base\",\"children\":\"Example: uniform distribution\"}]}],[\"$\",\"div\",null,{\"className\":\"px-4 py-3 text-base leading-relaxed\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"Let's see why this is true on an example. Take a sequence of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\" fair coin flips. This is a uniform distribution over \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"2\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"2^n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6644em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"2\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.6644em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"n\"}]}]]}]}]}]}]}]]}]]}]}]]}],\" binary strings of length \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\". The entropy of this distribution is \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\". Now let's examine the Kolmogorov complexity.\"]}],[\"$\",\"p\",null,{\"children\":[\"On one hand, the Kolmogorov complexity of any \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"-bit string is at most \",[\"$\",\"$L19\",null,{\"displayMode\":true,\"math\":\"K(\\\\underbrace{\\\\textsf{01000\\\\dots 010110}}_{\\\\textrm{$n$ bits}}) \\\\le n + \\\\textrm{something small}.\"}],\" That's because in any (reasonable) language, you can just print the string:\"]}],[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"print('01000...010110')\\n\"}]}],[\"$\",\"p\",null,{\"children\":[\"But can the average Kolmogorov complexity be much smaller than \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"? Notice that our uniform distribution contains many strings with very small Kolmogorov complexity, like the string \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"000\"}],[\"$\",\"mo\",null,{\"children\":\"…\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"000\\\\dots 0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6444em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"000\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"minner\",\"children\":\"…\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"0\"}]]}]}]]}],\". The reason why those special snowflakes don't really matter on average is \",[\"$\",\"$L16\",null,{\"href\":\"/08-coding_theory\",\"children\":\"coding theory\"}],\".\\nWe can construct a concrete code like this: for any string in our distribution, its code name is the shortest program that prints it.\",[\"$\",\"$L17\",null,{\"children\":[\"There is a subtlety here. Code has to be prefix-free: If \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mn\",null,{\"mathvariant\":\"sans-serif\",\"children\":\"0\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\mathsf{0}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6556em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathsf\",\"children\":\"0\"}]]}]}]]}],\" is a code, then \",[\"$\",\"$L19\",null,{\"math\":\"\\\\mathsf{01}\"}],\" can't be a code. So, to interpret a program as a code name, our programming language has to be prefix-free -- no program can be a prefix of another program. This can be done e.g. by appending a \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Null-terminated_string\",\"children\":\"null-character at the end of the string\"}],\", or writing its length at the beginning. \"]}],\" The average length of this code is exactly \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[K(x)]\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05764em\"},\"children\":\"E\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"[\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")]\"}]]}]}]]}],\". But \",[\"$\",\"$L16\",null,{\"href\":\"/08-coding_theory#source-coding\",\"children\":\"we have seen\"}],\" that any code has its average length at least as big as the entropy. Hence, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mo\",null,{\"children\":\"≥\"}],[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"X\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[K(x)] \\\\ge H(X) = n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05764em\"},\"children\":\"E\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"[\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")]\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"≥\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07847em\"},\"children\":\"X\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]]}]]}],\" and we have the formula:\"]}],[\"$\",\"$L19\",null,{\"displayMode\":true,\"math\":\"E[K(x)] \\\\approx H(X)\"}]]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"If you look at above proof sketch, you can notice that we did not really use that the distribution is uniform, it works pretty much for any distribution.\",[\"$\",\"$L17\",null,{\"children\":[\"There is an annoying detail. The distribution \",[\"$\",\"em\",null,{\"children\":\"itself\"}],\" can be hard to describe in the sense of having large Kolmogorov complexity. See e.g. 14.3 in \",[\"$\",\"$L16\",null,{\"href\":\"http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf\",\"children\":\"Elements of Information theory\"}],\". \"]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"However, the case of a uniform distribution is the most interesting: It tells us that most \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"-bit strings can't really be compressed, since their Kolmogorov complexity is close to \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"! In fact, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"-bit strings with Kolmogorov complexity \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"≥\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\ge n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.7719em\",\"verticalAlign\":\"-0.136em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"≥\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]]}]]}],\" are called \",[\"$\",\"em\",null,{\"children\":\"Kolmogorov random\"}],\", to highlight the insight that \",[\"$\",\"strong\",null,{\"children\":\"bits are random if we can't compress them\"}],\".\"]}],\"\\n\",[\"$\",\"$L1a\",null,{\"headline\":\"Long runs\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"Think of a long \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\"-bit string generated by flipping a fair coin \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\" times. What is the longest consecutive run of heads in such a string? You can use classical tools of probability theory like \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Chernoff_bound\",\"children\":\"Chernoff's inequality\"}],\" to compute that with high probability, the string won't contain runs of length more than \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"O\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"O(\\\\log n)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.02778em\"},\"children\":\"O\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\".\"]}],[\"$\",\"p\",null,{\"children\":[\"But there's also a more direct way to see this: If a bit string \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"s\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"s\"}]]}]}]]}],\" contains a large run of zeros of length \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"k\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"k\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}]]}]}]]}],\" at position \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"i\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"i\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6595em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"i\"}]]}]}]]}],\", i.e.,\"]}],[\"$\",\"$L19\",null,{\"displayMode\":true,\"math\":\"s = s_1 \\\\underbrace{00\\\\dots 0}_{k} s_2\"}],[\"$\",\"p\",null,{\"children\":[\"you need only store \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"s\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"k\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"s_1, s_2, k, i\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.8889em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"s\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"1\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"s\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"2\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"i\"}]]}]}]]}],\" in memory. The overhead to store a few additional numbers is definitely less than \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"10\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"10 \\\\log_2 n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9386em\",\"verticalAlign\":\"-0.2441em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"10\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.207em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.4559em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"2\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2441em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\" (the true constant factor is much better). The good part is that we store \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"k\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"k\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}]]}]}]]}],\" bits less. So, the Kolmogorov complexity of strings with pattern of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"k\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"k\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}]]}]}]]}],\" zeros is\"]}],[\"$\",\"$L19\",null,{\"displayMode\":true,\"math\":\"K(x) \\\\le n - k + 10\\\\log_2 n.\"}],[\"$\",\"p\",null,{\"children\":[\"If it was often the case that a random string contains a substring of zeros of length \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"\u003e\"}],[\"$\",\"mn\",null,{\"children\":\"10\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\u003e 10\\\\log_2n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5782em\",\"verticalAlign\":\"-0.0391em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"\u003e\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9386em\",\"verticalAlign\":\"-0.2441em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"10\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.207em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.4559em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"2\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2441em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]]}]]}],\", we could use this trick to compress random strings on average. But that's not possible, so random strings typically can't have long runs of zeros.\"]}],[\"$\",\"p\",null,{\"children\":[\"The true power of this view is that we can now understand why random strings can't have any long interesting patterns in them. If there were patterns, they would be predictable, and hence the strings compressible. But \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"E\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"]\"}],[\"$\",\"mo\",null,{\"children\":\"≥\"}],[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"X\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"E[K(x)] \\\\ge H(X) = n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05764em\"},\"children\":\"E\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"[\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")]\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"≥\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07847em\"},\"children\":\"X\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]]}]]}],\" says that this can't happen.\"]}]]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Prediction, compression, and the Chinese room\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In previous chapter, we talked about how prediction and compression are closely related. It may have looked a bit like some kind of algebraic trick - coincidentally, surprise is measured as \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"/\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\log 1/p\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"1/\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}]]}]}]]}],\" and lengths of good code name is also \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"/\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\log 1/p\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"1/\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}]]}]}]]}],\", so there's the connection between prediction and coding.\\nKolmogorov complexity gives a smooth language to talk about this connection. In particular, I find it especially helpful that we can talk about compression / Kolmogorov complexity without talking about probability distributions.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Let's say we want to discuss how LLMs are \\\"good at predicting the next token on Wikipedia\\\" and make it more mathematically precise. Using the language of cross-entropy and entropy is a bit awkward - it has to involve some kind of distribution over inputs. We have to imagine some kind of abstruse probability distribution \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"p\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"p\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}]]}]}]]}],\" over thoughts about the world written in English. Then, let \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" be the distribution over texts generated by running our LLM. The technical sense in which the LLM \\\"is good at predicting\\\" is that \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"H(p,q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" is small.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Using the language of compression, we can reformulate \\\"being good at predicting Wikipedia\\\" as \\\"being good at compressing Wikipedia\\\". For me, this is much more tangible! LLMs are simply smart enough not to find \\\"Wikipedia\\\" that surprising - as measured in bits that we have to store so that the LLM can recover the original text from them. This story about what's happening in LLMs does not require arguing about any distribution \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"p\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"p\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}]]}]}]]}],\" over all English texts.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Here's a concrete example that helps illustrate these concepts. A philosopher called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/John_Searle\",\"children\":\"John Searle\"}],\" once proposed a thought experiment called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Chinese_room\",\"children\":\"Chinese room\"}],\".\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Let me quickly explain the gist. \",[\"$\",\"$L17\",null,{\"children\":\"There are more ways to interpret what the experiment is getting at, this is one interpretation. \"}],\" If you are from the older generation like me, you might remember that pre-2022, there was a thing called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Turing_test\",\"children\":\"Turing test\"}],\":\",[\"$\",\"$L17\",null,{\"children\":\"Somehow, people stopped talking about it after GPT-4-level models. \"}],\" Imagine that you can chat for a few minutes with an entity that is either a human, or an AI impersonating a human. If you can't reliably tell the two cases apart, Turing claims that we should concede that the AI is intelligent.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"But Searle objects: What if the AI was just a long list of rules? (In his experiment, he imagines a person locked in a room with a Chinese conversation rulebook) This was actually how some pre-deep learning AIs faked their way through short (5 minutes) Turing test games. The AIs were just an incredibly long lists of pattern matching rules like \\\"If they seem to ask you about your favorite artist, tell them Madonna and ask them about their favorite artist. \\\" This works for very short conversations, since it was relatively predictable what kind of questions the human judges are typically asking.\"}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full flex justify-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded shadow-sm overflow-hidden bg-white\",\"style\":{\"maxWidth\":\"100%\"},\"children\":[\"$\",\"$L1b\",null,{\"src\":\"/fig/eliza.png\",\"alt\":\"ELIZA\",\"className\":\"max-w-full h-auto object-contain block\"}]}]}],[\"$\",\"div\",null,{\"className\":\"text-center text-sm italic font-medium text-gray-700 max-w-2xl mx-auto min-h-[1.5em] mt-0.5 px-4 py-0.5\",\"children\":[[\"$\",\"p\",\"p-0\",{\"children\":\"Pre-deep-learning chatbots like ELIZA are mostly just lists of common phrases, especially questions that pretend to be relevant. If you keep adding IFs and ELSEs, you get better models of human language. But there's no compression happenning, so the chatbot does not really generalize to new situations.\"}]]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The problem with this approach is that \",[\"$\",\"$L16\",null,{\"href\":\"https://arxiv.org/pdf/1108.1791\",\"children\":\"it gets exponentially harder\"}],\" - for each additional minute of the immitation game, the number of rules included in the intelligence fakers has to grow by a multiplicative factor. That's because there is no \",[\"$\",\"em\",null,{\"children\":\"compression\"}],\" happening in those programs - they were not trying to \",[\"$\",\"em\",null,{\"children\":\"predict\"}],\" what happens in human-like conversations, they were just trying to list all of them. Thus, such programs never really \",[\"$\",\"em\",null,{\"children\":\"generalized\"}],\", they did not lead to new, interesting insights. And, Searle has a very good point that even if the programs can fool people on Turing test for a few minutes, there is not really much of an \",[\"$\",\"em\",null,{\"children\":\"understanding\"}],\" happening.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"This is of course very different for current AIs. As we now understand, they are literally trained to \",[\"$\",\"em\",null,{\"children\":\"predict\"}],\" human conversations and writings. Or, equivalently, they are trying to \",[\"$\",\"em\",null,{\"children\":\"compress\"}],\" them. This compression is the crucial difference from the earlier Turing-test-fakers. The architects of current AI like Ilya Sutskever understand this difference extremely well and it was the reason why they were optimistic about the overall approach of training general intelligence by modelling text. They understood that being good on the \\\"simplistic\\\" task of predicting the next token does not only force you to learn English words (GPT-1) or the basic grammar of a couple of languages (GPT-2). To get really good at predicting the next token, you have to \",[\"$\",\"$L16\",null,{\"href\":\"https://www.dwarkesh.com/p/ilya-sutskever\",\"children\":\"understand the underlying reality that led to the creation of that token\"}],\". Understanding reality partially consists of learning facts, but more importantly, it requires intelligence to combine them. \",[\"$\",\"$L17\",null,{\"children\":[\"For some reason, people actually often use the Chinese room experiment to conclude that even the current AIs don't really understand the world, they are just '\",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Stochastic_parrot\",\"children\":\"stochastic parrots\"}],\"'. I find it quite confusing since I think of the experiment as a great argument for why current AI \",[\"$\",\"em\",null,{\"children\":\"does\"}],\" understand the world. \"]}]]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Solomonoff prior \u0026 induction\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"What's the most natural distribution over all (finite) binary strings, if what we care about is their Kolmogorov complexity? The \",[\"$\",\"$L16\",null,{\"href\":\"04-max_entropy\",\"children\":\"maximum entropy principle\"}],\" says we should consider the distribution \",[\"$\",\"$L19\",null,{\"math\":\"p(x) \\\\propto e^{- \\\\lambda K(x)}\"}],\", for some \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"λ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\lambda\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"λ\"}]]}]}]]}],\". In a minute, we will see that the right \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"λ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\lambda\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"λ\"}]]}]}]]}],\" is such that \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"∝\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"2\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"p(x) \\\\propto 2^{-K(x)}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"∝\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.888em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"2\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.888em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]}]}]}]}]]}]]}]]}]]}],\" \",[\"$\",\"$L17\",null,{\"children\":[\"A quick intuition: Larger \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"λ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\lambda\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"λ\"}]]}]}]]}],\" makes the weight of long algorithms negligible, and smaller \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"λ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\lambda\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"λ\"}]]}]}]]}],\" will likely not even be normalizable. \"]}],\" This distribution is called \",[\"$\",\"em\",null,{\"children\":\"Solomonoff prior\"}],\". \",[\"$\",\"$L17\",null,{\"children\":\"todo maybe mention universal probability. \"}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"It's called \",[\"$\",\"em\",null,{\"children\":\"prior\"}],\" because this is how we typically want to use this distribution. Similarly to other maximum entropy distributions, this is where should start before we start making observations and updating it. I find it philosophically very appealing, feel free to check the expand boxes.\"]}],\"\\n\",[\"$\",\"$L1a\",null,{\"advanced\":true,\"headline\":\"Solomonoff induction\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"The reason why Solomonoff came up with the prior is that he used it to develop what's known as \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference\",\"children\":\"Solomonoff induction\"}],\" - a theory formalizing how reasoning is supposed to be done. This all sounds very abstract, so imagine that you are given a mysterious machine\",[\"$\",\"$L17\",null,{\"children\":\"E.g. the universe if you are a physicist or LLM if you are a computer scientist. \"}],\" that you can poke into and it sometimes produces some outputs you can observe. You have a few hypotheses - models - for what's going on inside. The question is: what's the best model?\"]}],[\"$\",\"p\",null,{\"children\":[\"A partial answer to the question is Bayes' rule from \",[\"$\",\"$L16\",null,{\"href\":\"01-kl_intro\",\"children\":\"the first chapter\"}],\": Say that we start with some prior distribution over the models. Then, as we keep poking at the machine, we make observations that have different likelihoods under different models and Bayes' rule uses those likelihoods to update the prior.\"]}],[\"$\",\"p\",null,{\"children\":[\"But what prior should we start with? Solomonoff offers his. This way, if the model \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" has Kolmogorov \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"K(q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" and the log-likelihood of our observations under that hypothesis is \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"L\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"L(q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"L\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\", Bayes' rule says that in the posterior, the hypothesis probability will be proportional to \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"2\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"L\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"2^{- K(q) + L(q)}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.888em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"2\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.888em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"L\"}],[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]}]}]}]}]]}]]}]}]]}],\". That is, more complicated hypotheses are charged for their complexity by the prior. If you now want to select the most likely hypothesis, it should not be the one maximizing the log-likelihood (which is the suggestion of the \",[\"$\",\"$L16\",null,{\"href\":\"04-mle\",\"children\":\"maximum likelihood principle\"}],\"), we should additionally regularize by Kolmogorov complexity.\"]}],[\"$\",\"p\",null,{\"children\":[\"Here is a coding-theory intuition for why this makes sense. The hypothesis that is the most likely under Solomonoff prior is exactly the hypothesis that compresses the observed data the best. Remember, negative log-likelihood is just crossentropy. More concretely, if we use \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"p\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"p\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}]]}]}]]}],\" for the true distributions over the \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"n\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]}]]}],\" observations we see, we have \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"L\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}],[\"$\",\"mo\",null,{\"children\":\"⋅\"}],[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"L(q) = -n \\\\cdot H(p,q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"L\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6667em\",\"verticalAlign\":\"-0.0833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"⋅\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]]}]]}],\". So, maximizing \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"L\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"-K(q) + L(q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"L\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]]}]]}],\" is really the same as minimizing \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}],[\"$\",\"mo\",null,{\"children\":\"⋅\"}],[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"K(q) + n \\\\cdot H(p, q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4445em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"⋅\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]]}]]}],\". But this formula has very clear meaning - it is the number of bits needed to compress the observations by \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\". Indeed, we first have to store \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" and then use coding theory to compress the observations with \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"H(p,q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" bits per letter. \",[\"$\",\"$L17\",null,{\"children\":[\"Example: in our \",[\"$\",\"$L16\",null,{\"href\":\"08-coding_theory\",\"children\":\"coding theory chapter\"}],\", we discussed the Hutter's challenge. State-of-the-art LLMs have top-notch \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"H\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"H(p,q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.08125em\"},\"children\":\"H\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" on Wikipedia, but humongous \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"K(q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\". On the other hand, using optimal code has so negligible \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"K(q)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" for texts of nontrivial length that we did not even discuss it in the \",[\"$\",\"$L16\",null,{\"href\":\"09-coding-theory#compression\",\"children\":\"compression widget\"}],\" at that page. \"]}]]}]]}],\"\\n\",[\"$\",\"$L1a\",null,{\"advanced\":true,\"headline\":\"Solving epistemology\",\"children\":[[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 gap-4 mb-4 place-items-center justify-center mx-auto\",\"style\":{\"width\":\"fit-content\"},\"children\":[[\"$\",\"div\",\"0\",{\"style\":{\"height\":\"160px\",\"width\":\"100%\",\"maxWidth\":\"192px\",\"display\":\"flex\",\"alignItems\":\"center\",\"justifyContent\":\"center\",\"flexShrink\":0},\"className\":\"rounded shadow-sm overflow-hidden mx-auto bg-white\",\"children\":[\"$\",\"$L1b\",null,{\"src\":\"/fig/epikuros.jpg\",\"alt\":\"Epicurus\",\"className\":\"w-full h-full object-contain block\"}]}],[\"$\",\"div\",\"1\",{\"style\":{\"height\":\"160px\",\"width\":\"100%\",\"maxWidth\":\"192px\",\"display\":\"flex\",\"alignItems\":\"center\",\"justifyContent\":\"center\",\"flexShrink\":0},\"className\":\"rounded shadow-sm overflow-hidden mx-auto bg-white\",\"children\":[\"$\",\"$L1b\",null,{\"src\":\"/fig/William_of_Ockham.png\",\"alt\":\"William of Ockham\",\"className\":\"w-full h-full object-contain block\"}]}],[\"$\",\"div\",\"2\",{\"style\":{\"height\":\"160px\",\"width\":\"100%\",\"maxWidth\":\"192px\",\"display\":\"flex\",\"alignItems\":\"center\",\"justifyContent\":\"center\",\"flexShrink\":0},\"className\":\"rounded shadow-sm overflow-hidden mx-auto bg-white\",\"children\":[\"$\",\"$L1b\",null,{\"src\":\"/fig/hume.jpg\",\"alt\":\"David Hume\",\"className\":\"w-full h-full object-contain block\"}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"text-center text-sm italic font-medium text-gray-700 max-w-2xl mx-auto min-h-[1.5em] px-4 py-0.5 mt-0.5\",\"children\":[[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"a\",\"a-0\",{\"href\":\"https://en.wikipedia.org/wiki/Epicurus\",\"children\":\"Epicurus\"}],\" (~300 BC) is the father of Epicureanism - a school of thought which is a kind of like an early atheism. \",[\"$\",\"a\",\"a-1\",{\"href\":\"https://en.wikipedia.org/wiki/William_of_Ockham\",\"children\":\"William of Ockham\"}],\" (~1400) was a medieval philosopher, now mostly known for his razor. \",[\"$\",\"a\",\"a-2\",{\"href\":\"https://en.wikipedia.org/wiki/David_Hume\",\"children\":\"David Hume\"}],\" (~1750) was an enlightement empiricist, claiming that our reasoning should be tracable back to some experience with the world - That's why he was super interested in the problem of induction!\"]}]]}]]}],[\"$\",\"p\",null,{\"children\":[\"Imagine a special case of Solomonoff induction where each observation either is predicted by the model (likelihood = 1) or is not (likelihood = 0). Then, Solmonoff induction consists of crossing out models incompatible with data. The posterior distribution over the non-crossed models is very similar to the original Solomonoff prior: each hypothesis \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" has probability proportional to \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"2\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"K\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"2^{-K(q)}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.888em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"2\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.888em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"K\"}],[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]}]}]}]}]]}]]}]}]]}],\". This generalizes \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Occam%27s_razor\",\"children\":\"Occam's razor\"}],\" that says that we should prefer simple hypotheses, and \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Epicurus#Principle_of_Multiple_Explanations\",\"children\":\"Epicurus principle\"}],\" that says that if more hypothesis explain the data, we should not disregard any of them.\"]}],[\"$\",\"p\",null,{\"children\":[\"Years later, an enlightment philosopher \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/David_Hume\",\"children\":\"David Hume\"}],\" was struggling with \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Problem_of_induction\",\"children\":\"the problem of induction\"}],\". Basically: Even if we solve physics and find a perfectly good model of it \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" that fits everything that happened so far, what about a model \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q'\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9463em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.7519em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"′\"}]}]}]]}]}]}]}]}]]}]]}]}]]}],\" that is the same as \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" until tomorrow, but does some stupid rubbish afterwards? Hume was an empiricist and held that there's no good rational justification for preferring \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" over \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mo\",null,{\"mathvariant\":\"normal\",\"lspace\":\"0em\",\"rspace\":\"0em\",\"children\":\"′\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q'\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9463em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.7519em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"′\"}]}]}]]}]}]}]}]}]]}]]}]}]]}],\". But Solomonoff induction is a pretty good \\\"rational\\\" answer, if you ask me!\",[\"$\",\"$L17\",null,{\"children\":[\"Of course, whether this is a satisfying answer depends on how we justified using the Solomonoff prior in the first place. I kind of pulled it out of a hat, but there are \",[\"$\",\"$L16\",null,{\"href\":\"http://www.vetta.org/documents/Machine_Super_Intelligence.pdf\",\"children\":\"nice\"}],\" \",[\"$\",\"$L16\",null,{\"href\":\"https://link.springer.com/book/10.1007/978-0-387-49820-1\",\"children\":\"theorems\"}],\" showing that it's in a sense a unique probability distribution. \"]}],\" If you use that prior, you get Occam's razor: even if both hypotheses fit the data, the simpler one - \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"q\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"q\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]]}]}]]}],\" - is much more probable.\"]}]]}],\"\\n\",[\"$\",\"$L1a\",null,{\"advanced\":true,\"headline\":\"🐘 Von Neumann's elephant \u0026 overfitting\",\"children\":[[\"$\",\"p\",null,{\"children\":[[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/John_von_Neumann\",\"children\":\"John von Neumann\"}],\" \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Von_Neumann%27s_elephant\",\"children\":\"allegedly\"}],\" said \\\"With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.\\\" This quote famously illustrates the danger of \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Overfitting\",\"children\":[\"$\",\"em\",null,{\"children\":\"overfitting\"}]}],\": adding more parameters to a model can make it fit any data, but such a model won't generalize very well.\"]}],[\"$\",\"p\",null,{\"children\":\"The widget below shows von Neumann's elephant curve and other parametric curves. If you can make the elephant wiggle its trunk by adjusting the coefficients, let me know how you did it!\"}],[\"$\",\"$L1c\",null,{}]]}],\"\\n\",[\"$\",\"$L1a\",null,{\"advanced\":true,\"headline\":\"AIC \u0026 BIC model selection\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"In practice, we can't compute Kolmogorov complexity, but we can estimate it as the number of parameters in the model: Instead of simply taking the model with minimum crossentropy loss (MLE), we should add a term \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"C\"}],[\"$\",\"mo\",null,{\"children\":\"⋅\"}],[\"$\",\"mi\",null,{\"children\":\"k\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"C \\\\cdot k\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"C\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"⋅\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}]]}]]}]]}],\" to the overall loss. Here, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"k\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"k\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03148em\"},\"children\":\"k\"}]]}]}]]}],\" is the number of parameters and \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"C\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"C\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"C\"}]]}]}]]}],\" is 'how many bits per parameter'. If parameters are small numbers, we may opt for \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"C\"}],[\"$\",\"mo\",null,{\"children\":\"≈\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"C \\\\approx 1\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"C\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"≈\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6444em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"1\"}]]}]]}]]}],\". If the parameters are some kind of real numbers, it is typically more sensible to think about them as having \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"O\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"O(\\\\log n)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.02778em\"},\"children\":\"O\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" bits. The choice of \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"C\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"C = 1\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"C\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6444em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"1\"}]]}]]}]]}],\" is called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Akaike_information_criterion\",\"children\":\"AIC\"}],\" and \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"C\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mfrac\",null,{\"children\":[[\"$\",\"mn\",null,{\"children\":\"1\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"mi\",null,{\"children\":\"ln\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"C = \\\\frac{1}{2}\\\\ln n\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6833em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07153em\"},\"children\":\"C\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.1901em\",\"verticalAlign\":\"-0.345em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen nulldelimiter\"}],[\"$\",\"span\",null,{\"className\":\"mfrac\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.8451em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.655em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"2\"}]}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.23em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"frac-line\",\"style\":{\"borderBottomWidth\":\"0.04em\"}}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.394em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"1\"}]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.345em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"mclose nulldelimiter\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":\"ln\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"n\"}]]}]]}]]}],\" is called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Bayesian_information_criterion\",\"children\":\"BIC\"}],\". Both of these choices are typically justified by a different argument with some more concrete assumptions.\"]}],[\"$\",\"p\",null,{\"children\":[\"You can test both rules on the following widget that fits input points with a polynomial curve. The crossentropy is computed by so-called \",[\"$\",\"$L16\",null,{\"href\":\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\",\"children\":\"cross-validation\"}],\", and you can see how the choice of the best model slightly differs between MLE, AIC, and BIC.\"]}],[\"$\",\"$L1d\",null,{}]]}]],[\"$\",\"$L1e\",null,{\"headerLevel\":0}],[\"$\",\"$L1f\",null,{}],[\"$\",\"div\",null,{\"className\":\"mt-16 pt-8 border-t border-gray-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex justify-between items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L12\",null,{\"href\":\"/08-coding_theory/\",\"className\":\"inline-flex items-center text-blue-600 hover:text-blue-800 transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-5 h-5 mr-2\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M15 19l-7-7 7-7\"}]}],[\"$\",\"div\",null,{\"className\":\"text-left\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-500\",\"children\":\"Previous\"}],[\"$\",\"div\",null,{\"className\":\"font-medium\",\"children\":\"Coding theory\"}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1 text-right\",\"children\":null}]]}]}]]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:null\n"])</script><script>self.__next_f.push([1,"9:null\nd:[[\"$\",\"title\",\"0\",{\"children\":\"Bayes, bits \u0026 brains\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Bayes, bits \u0026 brains\"}]]\n"])</script></body></html>